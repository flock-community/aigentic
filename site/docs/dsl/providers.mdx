---
id: providers
title: Providers
sidebar_position: 2
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CodeBlock from '@theme/CodeBlock';

# Providers

Aigentic provides a consistent interface for working with different Large Language Model (LLM) providers. This allows you to easily switch between models or use multiple models in your application.

## Supported Models

Aigentic supports several LLM providers out of the box:

<Tabs>
  <TabItem value="OpenAI" label="OpenAI">
    <CodeBlock language="kotlin">
      {`val openAIModel = openAIModel {
    apiKey("your-api-key")
    modelIdentifier(OpenAIModelIdentifier.GPT4O)
    generationConfig {
        temperature(0.7f)
        topK(40)
        topP(0.95f)
    }
}`}
    </CodeBlock>
  </TabItem>

  <TabItem value="Gemini" label="Gemini">
    <CodeBlock language="kotlin">
      {`val geminiModel = geminiModel {
    apiKey("your-api-key")
    modelIdentifier(GeminiModelIdentifier.Gemini2_5Flash)
    generationConfig {
        temperature(0.2f)
        topK(40)
        topP(0.8f)
    }
}`}
    </CodeBlock>
  </TabItem>

  <TabItem value="Ollama" label="Ollama">
    <CodeBlock language="kotlin">
      {`val ollamaModel = ollamaModel {
    apiUrl("http://localhost:11434/v1/")
    modelIdentifier(OllamaModelIdentifier.Llama2)
    generationConfig {
        // Use default settings
    }
}`}
    </CodeBlock>
  </TabItem>

  <TabItem value="VertexAI" label="VertexAI">
    <CodeBlock language="kotlin">
      {`val vertexAIModel = vertexAIModel {
    project("your-project-id")
    location("your-location")
    modelIdentifier(VertexAIModelIdentifier.Gemini2_5Flash)
}`}
    </CodeBlock>
  </TabItem>
</Tabs>

## Bring your own model

All model implementations in Aigentic implement the `Model` interface, which defines the contract for interacting with LLM providers:

```kotlin
interface Model {
    val authentication: Authentication
    val modelIdentifier: ModelIdentifier
    val generationSettings: GenerationSettings

    suspend fun sendRequest(
        messages: List<Message>,
        tools: List<ToolDescription>,
    ): ModelResponse
}
```

You can implement this interface to connect to your own model
