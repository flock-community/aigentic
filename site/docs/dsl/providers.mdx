---
id: providers
title: Providers
sidebar_position: 2
---

# Providers

Aigentic provides a consistent interface for working with different Large Language Model (LLM) providers. This allows you to easily switch between models or use multiple models in your application.

## Supported Models

Aigentic supports several LLM providers out of the box:

### OpenAI

```kotlin
val openAIModel = openAIModel {
    apiKey("your-api-key")
    modelIdentifier(OpenAIModelIdentifier.GPT4O)
    generationConfig {
        temperature(0.7f)
        topK(40)
        topP(0.95f)
    }
}
```

### Gemini

```kotlin
val geminiModel = geminiModel {
    apiKey("your-api-key")
    modelIdentifier(GeminiModelIdentifier.Gemini2_5Flash)
    generationConfig {
        temperature(0.2f)
        topK(40)
        topP(0.8f)
    }
}
```

### Ollama

```kotlin
val ollamaModel = ollamaModel {
    apiUrl("http://localhost:11434/v1/")
    modelIdentifier(OllamaModelIdentifier.Llama2)
    generationConfig {
        // Use default settings
    }
}
```

### VertexAI

```kotlin
val vertexAIModel = vertexAIModel {
    project("your-project-id")
    location("your-location")
    modelIdentifier(VertexAIModelIdentifier.Gemini2_5Flash)
}
```

## Bring your own model

All model implementations in Aigentic implement the `Model` interface, which defines the contract for interacting with LLM providers:

```kotlin
interface Model {
    val authentication: Authentication
    val modelIdentifier: ModelIdentifier
    val generationSettings: GenerationSettings

    suspend fun sendRequest(
        messages: List<Message>,
        tools: List<ToolDescription>,
    ): ModelResponse
}
```

You can implement this interface to connect to your own model
